# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# Projeto: fiap_sprint4_reply

## Atividade em Grupo: FIAP - 1TIAOB - 2025/1 - Fase6 Sprint 4 - Reply

## üë®‚Äçüéì Integrantes: 
- <a href="">Alice C. M. Assis - RM 566233</a>
- <a href="">Leonardo S. Souza - RM 563928</a>
- <a href="">Lucas B. Francelino - RM 561409</a>
- <a href="">Pedro L. T. Silva - RM 561644</a>
- <a href="">Vitor A. Bezerra - RM 563001</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="proflucas.moreira@fiap.com.br">Lucas Gomes Moreira</a>
### Coordenador(a)
- <a href="profandre.chiovato@fiap.com.br">Andr√© Godoi Chiovato</a>
- 
****

# 1. V√≠deo e deploy do projeto na nuvem:

INSERIR VIDEO AQUI

- Link do v√≠deo: LINK AQUI

Sobre o deploy na nuvem, o grupo realizou o deploy do projeto no ambiente "AWS Academy". No entanto, este ambiente fica dispon√≠vel no per√≠odo de apenas 4 horas, sendo encerrado automaticamente ap√≥s este per√≠odo.
Assim, caso queiram o link do projeto rodando na nuvem, pedimos a gentileza de entrar em contato com o grupo para que possamos iniciar o ambiente e disponibilizar o link do dashboard, conforme print abaixo:

<p align="center">
<img src="assets/deploy/console_aws_academy.png" alt="console_aws_academy" border="0" width=40% height=40%>
</p>

N√£o obstante, tendo visto esta limita√ß√£o, o grupo adicionou neste Readme o passo a passo de como fazer o deploy de todo o projeto facilmente na nuvem utilizando Terraform e AWS CLI, conforme explicado na se√ß√£o "Deploy na Nuvem AWS com Terraform".

Posto isto, tamb√©m √© poss√≠vel fazer o deploy do projeto na sua pr√≥pria conta AWS, bastando seguir as instru√ß√µes da se√ß√£o "Deploy na Nuvem AWS com Terraform".

# 2. Descri√ß√£o e Objetivos

Esta entrega tem como objetivo principal integrar todos os componentes desenvolvidos nas Entregas 1, 2 e 3 em um pipeline funcional, capaz de simular ou executar o fluxo completo de dados, desde a coleta at√© a visualiza√ß√£o e gera√ß√£o de alertas. O pipeline deve contemplar:

- Coleta/ingest√£o de dados a partir do ESP32 (real ou simulado via Wokwi/VSCode/PlatformIO), com pelo menos um sensor ativo, gerando leituras vari√°veis.
- Persist√™ncia dos dados coletados em um banco de dados relacional, conforme o modelo l√≥gico (DER) e as tabelas definidas anteriormente.
- Treinamento e/ou infer√™ncia de um modelo b√°sico de Machine Learning utilizando os dados armazenados, com apresenta√ß√£o de ao menos uma m√©trica relevante (ex: acur√°cia, MAE) e uma visualiza√ß√£o pertinente (ex: curva de previs√£o, matriz de confus√£o).
- Visualiza√ß√£o dos resultados em um dashboard ou relat√≥rio, exibindo KPIs do processo (ex: m√©dia/varia√ß√£o do sensor, score do modelo, n√∫mero de alertas) e implementa√ß√£o de alertas simples baseados em thresholds ou regras definidas.

---

## üìå Resumo do Fluxo do Projeto

1. **Coleta de Dados:** ESP32 (real ou simulado) l√™ sensores e envia dados via HTTP para a API.
2. **Ingest√£o:** API FastAPI recebe e armazena os dados no banco relacional.
3. **Persist√™ncia:** Dados salvos em PostgreSQL conforme DER definido.
4. **Machine Learning:** Treinamento/infer√™ncia de modelos com PyCaret usando dados do banco.
5. **Visualiza√ß√£o:** Dashboard Streamlit exibe KPIs, gr√°ficos e alertas em tempo real.
6. **Notifica√ß√µes:** Alertas autom√°ticos por e-mail via AWS SNS quando houver previs√£o do Machine Learing.

---

## üîó Entregas Anteriores e Integra√ß√£o

| Fase/Entrega | Reposit√≥rio/Link | Descri√ß√£o/Integra√ß√£o                                                                                   |
|--------------|------------------|--------------------------------------------------------------------------------------------------------|
| Sprint 1     | [Sprint 1](https://github.com/Hinten/fiap_sprint1_reply) | Planejamento da arquitetura inicial e defini√ß√£o dos blocos do pipeline.                                |
| Sprint 2     | [Sprint 2](https://github.com/Hinten/fiap_sprint2_reply) | Simula√ß√£o do circuito ESP32 e sensores, envio de dados para API local e modelagem do banco relacional. |
| Sprint 3     | [Sprint 3](https://github.com/Lesasouza/fiap_sprint3_reply) | Primeiros experimentos de ML.                                                                          |
| Sprint 4     | (Este reposit√≥rio) | Integra√ß√£o completa: coleta, ingest√£o, persist√™ncia, ML, dashboard e alertas.                          |

> **Como as entregas se conectam:**  
> Cada fase evoluiu o projeto, partindo do planejamento (Sprint 1), passando pela simula√ß√£o e ingest√£o de dados (Sprint 2), treinamento de IA (Sprint 3), at√© a integra√ß√£o total e observabilidade (Sprint 4). O pipeline final costura todos os componentes, garantindo reprodutibilidade e rastreabilidade.

---

# 3. Justificativa dos Sensores Escolhidos

- **Sensor de Temperatura (MPU6050):** Permite monitorar o aquecimento de equipamentos, prevenindo falhas por superaquecimento.
- **Sensor de Vibra√ß√£o (MPU6050):** Essencial para identificar padr√µes anormais que podem indicar desgaste ou mau funcionamento de m√°quinas.
- **Sensor de Luminosidade (LDR):** √ötil para monitorar ambientes industriais onde a ilumina√ß√£o pode impactar processos ou seguran√ßa.

Esses sensores foram escolhidos por serem amplamente utilizados em ambientes industriais e facilmente simul√°veis no Wokwi.

# 4. Esquema do Circuito Simulado

O circuito simulado √© o mesmo feito quando da entrega 2 (https://github.com/Hinten/fiap_sprint2_reply), foram feitas pequenas modifica√ß√µes, principalmente na conex√£o WIFI e vari√°veis de ambiente, para que o ESP32 consiga se conectar a API local e enviar os dados dos sensores.

<p align="center">
  <img src="assets/ciruito.JPG" alt="Circuito Sensor" border="0" width=70% height=70%>
</p>

- O ESP32 est√° conectado ao sensor MPU6050 (I2C) e ao LDR (anal√≥gico).
- LED, rel√© e buzzer s√£o usados para alertas visuais e sonoros.
- O LCD exibe informa√ß√µes em tempo real sobre os sensores.

## Conex√£o com o Wi-Fi e envio de dados para a API

Para que a simula√ß√£o funcione corretamente, √© necess√°rio configurar a conex√£o com o Wi-Fi simulado do Wokwi e definir o IP do servidor local da API.

Assim, √© necess√°rio alterar o arquivo [.env](src/wokwi/.env) do Wokwi e setar a vari√°vel 'API_URL' para 'http://**IP DE SUA M√ÅQUINA NA REDE LOCAL**:8180', conforme exemplo abaixo:

```plaintext
API_URL=http://192.168.0.1:8180
```

> NOTA1: N√£o sete o IP da API para localhost ou 127.0.0.1, pois o ESP32 n√£o conseguir√° se conectar a ele. O localhost do ESP32 √© o pr√≥prio ESP32, e n√£o a m√°quina onde o servidor est√° rodando.

> NOTA2: Caso voc√™ esteja rodando a simula√ß√£o e mesmo assim o ESP32 n√£o consiga se conectar √† API, verifique se o firewall da sua m√°quina est√° bloqueando a porta 8180. Se estiver, libere a porta para que o ESP32 consiga se conectar.

> NOTA3: Caso voc√™ fa√ßa o deploy do projeto na nuvem AWS (conforme explicado abaixo), o script ir√° atualizar automaticamente a vari√°vel API_URL para o ip da api na nuvem, n√£o sendo necess√°ria nenhuma a√ß√£o pelo usu√°rio.

Ap√≥s configurado o arquivo [.env](src/wokwi/.env), voc√™ poder√° iniciar a simula√ß√£o do ESP32 no Wokwi. O circuito ir√° coletar os dados dos sensores e envi√°-los para a API, que por sua vez ir√° armazenar os dados no banco de dados.

## Registro do Funcionamento da Simula√ß√£o

As leituras dos sensores s√£o coletadas pelo ESP32 e enviadas automaticamente para a API via requisi√ß√µes HTTP. O envio ocorre a cada ciclo de leitura, garantindo que os dados estejam sempre atualizados no banco de dados para an√°lise posterior. O monitor serial e o display LCD exibem em tempo real as leituras e alertas, enquanto a API armazena cada registro recebido.

- **Print do Monitor Serial:**

<p align="center">
  <img src="assets/print_monitor_serial.JPG" alt="Monitor Serial" border="0" width=70% height=70%>
</p>

- **Print do LCD:**

<p align="center">
  <img src="assets/print_lcd.JPG" alt="LCD" border="0" width=70% height=70%>
</p>


# 5. API para salvar os dados do sensor

Neste projeto, foi implementada uma API b√°sica utilizando o FastAPI para receber os dados do sensor e armazen√°-los no banco de dados. A API permite que o ESP32 envie as leituras dos sensores, que s√£o ent√£o salvas no banco de dados para posterior an√°lise e visualiza√ß√£o.

A API pode ser executada separadamente executando o arquivo [api_basica.py](src/api/api_basica.py).

Explica√ß√µes mais detalhadas sobre como iniciar a api ser√£o apresentadas na se√ß√£o "Instalando e Executando o Projeto", a seguir neste mesmo README.md.

# 6. Armazenamento de Dados em Banco SQL com Python

<p align="center">
  <img src="assets/DER.png" alt="DER" border="0" width=70% height=70%>
</p>


<p align="center">
  <img src="assets/mer.png" alt="MER" border="0" width=70% height=70%>
</p>

Modelo de Entidade-Relacionamento:

Tabela: MANUTENCAO_EQUIPAMENTO
  - id (INTEGER NOT NULL) [PK]
  - equipamento_id (INTEGER NOT NULL) [FK -> EQUIPAMENTO]
  - data_previsao_manutencao (DATETIME)
  - motivo (TEXT)
  - data_inicio_manutencao (DATETIME)
  - data_fim_manutencao (DATETIME)
  - descricao (TEXT)
  - observacoes (TEXT)
  - custo (FLOAT)

Tabela: EQUIPAMENTO
  - id (INTEGER NOT NULL) [PK]
  - nome (VARCHAR(255) NOT NULL)
  - modelo (VARCHAR(255))
  - localizacao (VARCHAR(255))
  - descricao (TEXT)
  - observacoes (TEXT)
  - data_instalacao (DATETIME)

Tabela: TIPO_SENSOR
  - id (INTEGER NOT NULL) [PK]
  - nome (VARCHAR(255) NOT NULL)
  - tipo (VARCHAR(15) NOT NULL)

Tabela: SENSOR
  - id (INTEGER NOT NULL) [PK]
  - tipo_sensor_id (INTEGER NOT NULL) [FK -> TIPO_SENSOR]
  - limiar_manutencao_maior (FLOAT)
  - limiar_manutencao_menor (FLOAT)
  - nome (VARCHAR(255))
  - cod_serial (VARCHAR(255))
  - descricao (VARCHAR(255))
  - data_instalacao (DATETIME)
  - equipamento_id (INTEGER) [FK -> EQUIPAMENTO]

Tabela: LEITURA_SENSOR
  - id (INTEGER NOT NULL) [PK]
  - sensor_id (INTEGER NOT NULL) [FK -> SENSOR]
  - data_leitura (DATETIME NOT NULL)
  - valor (FLOAT NOT NULL)

Tabela: EMPRESA
  - id (INTEGER NOT NULL) [PK]
  - nome (VARCHAR(255) NOT NULL)
  - cnpj (VARCHAR(14))
  - logradouro (VARCHAR(255))
  - numero (VARCHAR(255))
  - bairro (VARCHAR(255))
  - cidade (VARCHAR(255))
  - estado (VARCHAR(2))
  - cep (VARCHAR(8))

A modelagem do banco de dados foi pensada para garantir a rastreabilidade, integridade e flexibilidade do sistema de monitoramento de sensores e equipamentos. Abaixo, explico o motivo da inclus√£o de cada entidade e campo:

**Tabela: EMPRESA**
***Permite registrar informa√ß√µes das empresas respons√°veis pelos equipamentos monitorados, facilitando a gest√£o multiempresa.***
- **id**: Identificador √∫nico da empresa, fundamental para relacionamentos e integridade dos dados.
- **nome**: Permite identificar a empresa de forma √∫nica no sistema.
- **cnpj**: Cadastro Nacional da Pessoa Jur√≠dica, essencial para valida√ß√£o e identifica√ß√£o fiscal.
- **logradouro, numero, bairro, cidade, estado, cep**: Campos necess√°rios para armazenar o endere√ßo completo da empresa, facilitando localiza√ß√£o e contato.

**Tabela: EQUIPAMENTO**
***Representa cada m√°quina ou dispositivo monitorado, permitindo associar sensores e manuten√ß√µes.***
- **id**: Identificador √∫nico do equipamento, necess√°rio para relacionamentos e controle individual.
- **nome**: Nome do equipamento, facilita a identifica√ß√£o e evita duplicidade.
- **modelo**: Permite diferenciar equipamentos do mesmo tipo, mas de modelos distintos.
- **localizacao**: Indica onde o equipamento est√° instalado, importante para manuten√ß√£o e monitoramento.
- **descricao**: Campo para detalhar caracter√≠sticas espec√≠ficas do equipamento.
- **observacoes**: Espa√ßo para anota√ß√µes gerais, como hist√≥rico de uso ou particularidades.
- **data_instalacao**: Registra quando o equipamento foi instalado, √∫til para controle de manuten√ß√£o preventiva.

**Tabela: TIPO_SENSOR**
***Define os tipos de sensores dispon√≠veis (ex: temperatura, vibra√ß√£o), facilitando a categoriza√ß√£o e expans√£o futura.***
- **id**: Identificador √∫nico do tipo de sensor.
- **nome**: Nome do tipo de sensor, garante unicidade e facilita buscas.
- **tipo**: Especifica a categoria do sensor (ex: temperatura, umidade), importante para valida√ß√£o e processamento dos dados.

**Tabela: SENSOR**
***Representa cada sensor f√≠sico instalado, permitindo rastrear leituras e manuten√ß√µes.***
- **id**: Identificador √∫nico do sensor.
- **tipo_sensor_id**: Relaciona o sensor ao seu tipo, garantindo integridade e padroniza√ß√£o.
- **limiar_manutencao_maior**: Define o valor m√°ximo aceit√°vel para o sensor, acionando alertas quando ultrapassado.
- **limiar_manutencao_menor**: Define o valor m√≠nimo aceit√°vel para o sensor, acionando alertas quando ultrapassado.
- **nome**: Nome do sensor, facilita a identifica√ß√£o.
- **cod_serial**: C√≥digo serial do sensor, importante para rastreabilidade f√≠sica.
- **descricao**: Detalhes adicionais sobre o sensor.
- **data_instalacao**: Data de instala√ß√£o do sensor, relevante para manuten√ß√£o e hist√≥rico.
- **equipamento_id**: Relaciona o sensor ao equipamento onde est√° instalado, permitindo rastrear medi√ß√µes por equipamento.

**Tabela: LEITURA_SENSOR**
***Armazena cada leitura realizada pelos sensores, base para an√°lises e alertas.***
- **id**: Identificador √∫nico da leitura.
- **sensor_id**: Relaciona a leitura ao sensor correspondente, garantindo rastreabilidade.
- **data_leitura**: Data e hora da leitura, essencial para an√°lises temporais.
- **valor**: Valor capturado pelo sensor, principal dado para monitoramento e an√°lise.
- 
**Tabela: MANUTENCAO_EQUIPAMENTO**
***ermite registrar manuten√ß√µes preventivas e corretivas dos equipamentos, integrando hist√≥rico operacional.***
- **id**: Identificador √∫nico da manuten√ß√£o.
- **equipamento_id**: Relaciona a manuten√ß√£o ao equipamento.
- **data_previsao_manutencao**: Data prevista para manuten√ß√£o.
- **motivo**: Motivo da manuten√ß√£o.
- **data_inicio_manutencao, data_fim_manutencao**: Per√≠odo da manuten√ß√£o.
- **descricao, observacoes**: Detalhes e anota√ß√µes sobre a manuten√ß√£o.
- **custo**: Valor gasto na manuten√ß√£o.

Cada entidade e campo foi inclu√≠do para garantir a integridade dos dados, facilitar consultas e permitir a expans√£o futura do sistema, como integra√ß√£o com novos tipos de sensores, equipamentos ou empresas.

## Models e Python

Para realizar a convers√£o das linhas e colunas da database para Python, foram definidas classes as quais s√£o respons√°veis por fazer as opera√ß√µes CRUD e demais funcionalidades do banco de dados.
Essas classes podem ser encontradas na pasta `src/database/models`, e todas elas herdam a classe principal chamada [Model](src/database/tipos_base/model.py).

## Script de Cria√ß√£o do Banco de Dados

O script para cria√ß√£o do banco de dados e tabelas pode ser encontrado no arquivo [assets/table_creation.ddl](assets/table_creation.ddl).
**Este script n√£o precisa ser executado manualmente, pois o banco de dados √© criado automaticamente ao iniciar o dashboard ou API.**

# 8. Instalando e Executando o Projeto

O sistema foi desenvolvido em Python e utiliza um banco de dados SQLite para armazenar os dados. O c√≥digo √© modularizado, permitindo f√°cil manuten√ß√£o e expans√£o.

## üì¶ Requisitos
- *Python 3.11.9*

## üìÇ Instala√ß√£o

- Instale as depend√™ncias utilizando o arquivo requirements.txt:
    ```bash
    pip install -r requirements.txt
    ```

- Para iniciar o dashboard interativo, execute o seguinte comando no terminal:
    ```bash
    streamlit run main_dash.py
    ```

- Para iniciar a api, execute o seguinte comando no terminal:
    ```bash
    uvicorn src.api.api_basica:app --host 0.0.0.0 --port 8180
    ```

## Arquivo de Configura√ß√£o

O projeto utiliza um arquivo especial denominado **`.env`** para armazenar vari√°veis de ambiente sens√≠veis, como credenciais de banco de dados e chaves de APIs externas. Por raz√µes de seguran√ßa, esse arquivo **n√£o deve ser compartilhado publicamente**.

### üìÑ O que √© o `.env`?

O `.env` √© um arquivo-texto simples, onde cada linha define uma vari√°vel de ambiente no formato `NOME_VARIAVEL=valor`. Esse m√©todo permite separar informa√ß√µes confidenciais do c√≥digo-fonte, facilitando a configura√ß√£o do sistema para diferentes ambientes (desenvolvimento, testes, produ√ß√£o, etc).

### üîë Vari√°veis Utilizadas

O projeto utiliza vari√°veis de ambiente para configura√ß√£o dos servi√ßos, bancos de dados e integra√ß√µes. Abaixo est√£o as principais vari√°veis utilizadas:

**Vari√°veis Gerais:**
- `LOGGING_ENABLED`: Ativa/desativa logs detalhados (`true` ou `false`).
- `ENABLE_API`: Ativa/desativa a API (`true` ou `false`).
- `ORACLE_DB_FROM_ENV`: Usa vari√°veis de ambiente para conex√£o Oracle (`true` ou `false`).
- `SQL_LITE`: Usa SQLite como banco de dados (`true` ou `false`).

**Vari√°veis do PostgreSQL:**
- `POSTGRE_DB_FROM_ENV`: Usa vari√°veis de ambiente para conex√£o PostgreSQL (`true` ou `false`).
- `POSTGRE_USER`: Usu√°rio do banco PostgreSQL.
- `POSTGRE_PASSWORD`: Senha do banco PostgreSQL.
- `POSTGRE_DB`: Nome do banco PostgreSQL.
- `POSTGRE_HOST`: Host do banco PostgreSQL.
- `POSTGRE_PORT`: Porta do banco PostgreSQL.

**Vari√°veis AWS/SNS:**
- `AWS_ACCESS_KEY_ID`: Chave de acesso AWS.
- `AWS_SECRET_ACCESS_KEY`: Chave secreta AWS.
- `AWS_SESSION_TOKEN`: Token de sess√£o AWS (opcional).
- `SNS_TOPIC_ARN`: ARN do t√≥pico SNS para notifica√ß√µes.
- `SNS_REGION`: Regi√£o AWS do SNS.

**Portas dos Servi√ßos:**
- `DASHBOARD_PORT`: Porta exposta para o dashboard (padr√£o: 8501).
- `API_PORT`: Porta exposta para a API (padr√£o: 8180).

**Vari√°vel de Simula√ß√£o Wokwi:**
- `API_URL`: URL da API para envio dos dados do ESP32 (exemplo: `http://192.168.0.60:8180`).

# 9. Deploy na Nuvem AWS com Terraform

Para facilitar o deploy e os testes do sistema, foi adotada uma abordagem automatizada utilizando Terraform e AWS CLI para provisionamento da infraestrutura na nuvem AWS.

## Diagrama da Arquitetura

<p align="center">
  <img src="assets/Diagrama_reply.drawio.png" alt="Diagrama da arquitetura" border="0" width=70% height=70%>
</p>

Comparado com o primeiro planejamento, que pode ser visto no github https://github.com/Hinten/fiap_sprint1_reply, o projeto vem evoluindo bem, estando quase todo o planejamento inicial implementado, faltando apenas pequenos apontamentos e otimiza√ß√µes.

## Pr√©-requisitos

- **Terraform** instalado na m√°quina local ([documenta√ß√£o oficial](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli)).
- **AWS CLI** instalado ([documenta√ß√£o oficial](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)).
- **Credenciais da AWS CLI configuradas** (comando `aws configure`), utilizando uma conta AWS v√°lida.

## Observa√ß√£o sobre Custos

> **Aten√ß√£o:** O deploy da infraestrutura na AWS gera um pequeno custo de centavos de d√≥lar por dia, principalmente devido √† cria√ß√£o da VPC (Virtual Private Cloud) e recursos associados. Recomenda-se destruir a infraestrutura ap√≥s os testes para evitar cobran√ßas desnecess√°rias.

## Como realizar o deploy

1. Acesse a pasta `iac/dev` do projeto.
2. Execute os comandos do Terraform para inicializar e aplicar a infraestrutura:

```cmd
cd iac\dev
terraform init
terraform apply
```

3. Confirme a aplica√ß√£o quando solicitado. O Terraform ir√° provisionar toda a infraestrutura necess√°ria na AWS.

4. Para destruir a infraestrutura e evitar custos:

```cmd
terraform destroy
```

## Executando o deploy da aplica√ß√£o no servidor

Ap√≥s a cria√ß√£o da infraestrutura, √© necess√°rio rodar o script `deploy_app_server.bat` na raiz do projeto. Esse script automatiza o processo de:
- Obter o IP p√∫blico da inst√¢ncia criada pelo Terraform.
- Copiar os arquivos necess√°rios (c√≥digo, Dockerfiles, docker-compose, vari√°veis de ambiente) para o servidor EC2 via SSH/SCP.
- Instalar Docker, Docker Compose e Git na m√°quina remota.
- Clonar o reposit√≥rio do projeto na m√°quina EC2.
- Corrigir permiss√µes e preparar o ambiente.

> **Por que usar esse script?**
>
> O build da imagem Docker diretamente na nuvem √© mais r√°pido para testes, pois a imagem local pode ser muito grande (ex: 1.6GB devido ao PyCaret). Embora n√£o seja a abordagem ideal para produ√ß√£o, agiliza o deploy e os testes durante o desenvolvimento.

Ap√≥s rodar o script, o ambiente estar√° pronto, sendo printados no terminal as urls do dashboard e da api.

## Justificativa da abordagem

Esta estrat√©gia foi adotada para agilizar o deploy e os testes do sistema durante o desenvolvimento, permitindo r√°pida cria√ß√£o e remo√ß√£o do ambiente de nuvem.

No futuro, iremos aprimorar o processo, realizando o build da imagem Docker localmente e enviando-a para um reposit√≥rio (como Amazon ECR ou Docker Hub), ou ainda adotando um pipeline de CI/CD para automa√ß√£o completa do deploy, garantindo maior controle, seguran√ßa e escalabilidade.

# 10. Treinamento do modelo de Machine Learning

Comparado ao trabalho anterior, constante no github https://github.com/Lesasouza/fiap_sprint3_reply, foi elaborada uma nova View de treinamento de modelos de Machine Learning no dashboard utilizando o Pycaret.

<p align="center">
  <img src="assets/train_model/train_model.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

Essa nova View permite que o usu√°rio treine v√°rios modelos diferentes de Machine Learning com apenas um clique, utilizando a biblioteca PyCaret para simplificar o processo.

<p align="center">
  <img src="assets/train_model/train_model2.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

O user pode selecionar a m√©trica que deseja otimizar (ex: Acur√°cia, F1-Score, ROC AUC) e o sistema treina automaticamente v√°rios modelos, apresentando os resultados em uma tabela interativa, mostrando visualiza√ß√µes pertinentes, como a matriz de confus√£o e posteriormente salva o melhor modelo.

<p align="center">
  <img src="assets/train_model/train_model3.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

<p align="center">
  <img src="assets/train_model/train_model4.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

<p align="center">
  <img src="assets/train_model/train_model5.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

<p align="center">
  <img src="assets/train_model/train_model6.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

<p align="center">
  <img src="assets/train_model/train_model7.JPG" alt="Train Model View" border="0" width=70% height=70%>
</p>

# 11. üìä Notifica√ß√µes via EMAIL

O sistema implementa notifica√ß√µes autom√°ticas via email utilizando o servi√ßo Amazon SNS (Simple Notification Service) da AWS. Para que o user receba as notifica√ß√µes, √© necess√°rio configurar o servi√ßo SNS na AWS e adicionar o email do destinat√°rio como assinante do t√≥pico SNS.

<p align="center">
  <img src="assets/notificacoes/subscricao_email.JPG" alt="Subscri√ß√£o Email" border="0" width=70% height=70%>
</p>

Ap√≥s a adicionar o email, o usu√°rio receber√° um email de confirma√ß√£o, sendo necess√°rio clicar no link para confirmar a subscri√ß√£o.

<p align="center">
  <img src="assets/notificacoes/subscricao_email_confirmar.JPG" alt="Confirmar Subscri√ß√£o Email" border="0" width=70% height=70%>
</p>

Confirmada a subscri√ß√£o, o usu√°rio come√ßar√° a receber as notifica√ß√µes enviadas pelo sistema. Para ter certeza que o email est√° funcionando, o usu√°rio pode enviar um email de teste clicando no bot√£o "Enviar E-mail de Teste".

# 12. üìä Visualiza√ß√£o de leituras em tempo real e notifica√ß√£o de alertas

A p√°gina principal do aplicativo se tornou uma View para visualiza√ß√£o das leituras dos sensores em tempo real, com gr√°ficos atualizados a cada 60 segundos.

> Nota: Tentamos implementar atualiza√ß√µes em um per√≠odo de tempo menor, mas aparentemente o Streamlit tem um memoryleak que acaba congelando a m√°quina. Estamos trabalhando para solucionar esse problema nas pr√≥ximas entregas.
 
<p align="center">
  <img src="assets/tempo_real/tempo_real.JPG" alt="Tempo Real" border="0" width=70% height=70%>
</p>

Caso o user cadastre um sensor com limiares de alerta, nos campos "Limiar De Manuten√ß√£o Maior" ou "Limiar De Manuten√ß√£o Menor" o gr√°fico de visualiza√ß√£o mostrar√° linhas as quais apontam que as leituras est√£o ultrapassando os limiares, conforme abaixo:.
 
<p align="center">
  <img src="assets/notificacoes/tempo_real_limiar.JPG" alt="Tempo Real" border="0" width=70% height=70%>
</p>
 
<p align="center">
  <img src="assets/notificacoes/tempo_real_limiar.JPG" alt="Tempo Real" border="0" width=70% height=70%>
</p>

Por fim, nesta p√°gina, o user poder√° fazer previs√µes com os valores das leituras em tempo real, clicando no bot√£o "Fazer Previs√£o", caso o modelo identifique que a manuten√ß√£o √© necess√°ria, o user poder√° enviar um email de alerta clicando no bot√£o "Enviar Alerta de Manuten√ß√£o".
 
<p align="center">
  <img src="assets/notificacoes/tempo_real_limiar_previsao_alerta.JPG" alt="Tempo Real" border="0" width=70% height=70%>
</p>

# 13. Previs√£o Manual com Modelos Treinados

Tamb√©m √© poss√≠vel realizar previs√µes manuais utilizando modelos de machine learning previamente treinados e salvos em arquivos .joblib, conforme demonstrado na imagem abaixo:

<img width="1437" height="777" alt="image" src="assets/manual.png" />

ü§ñ Classificador de Equipamentos

Este m√≥dulo fornece uma interface em Streamlit para carregar modelos de machine learning previamente treinados (arquivos .joblib) e realizar previs√µes manuais com base em caracter√≠sticas inseridas pelo usu√°rio.

üöÄ Funcionalidades

‚úÖ Carregamento din√¢mico de modelos de classifica√ß√£o salvos em .joblib.

‚úÖ Interface simples para entrada de dados (Lux, Temperatura, Vibra√ß√£o).

‚úÖ Previs√£o com retorno textual:

"Manuten√ß√£o Necess√°ria"

"Sem Manuten√ß√£o Necess√°ria"

‚úÖ Sele√ß√£o do modelo desejado atrav√©s de um menu interativo.

üìä Exemplo de Uso
Entrada:

Lux = 15

Temperatura = 14

Vibra√ß√£o = 0

Sa√≠da:

‚úÖ Sem Manuten√ß√£o Necess√°ria
(ou)

‚ö†Ô∏è Manuten√ß√£o Necess√°ria


# 14. Importando a Base de dados utilizada pelo Grupo

As tabelas com os dados utilizados no sistema podem ser encontradas na pasta em [assets/database_export.zip](assets/database_export.zip).

O Grupo disponibilizou uma base de dados inicial para facilitar o uso do sistema. Para importar essa base de dados, siga os passos abaixo:

1. O usu√°rio deve selecionar a op√ß√£o "Importar Banco de Dados" no menu principal.
<p align="center">
  <img src="assets/dashboard/importar_banco_de_dados/importar_bd_1.JPG" alt="importar_db" border="0" width=80% height=80%>
</p>

2. Selecione o arquivo ZIP localizado em [assets/database_export.zip](assets/database_export.zip), espere carregar, role a p√°gina at√© o final e clique no bot√£o "Salvar no Banco de Dados".
<p align="center">
  <img src="assets/dashboard/importar_banco_de_dados/importar_bd_2.JPG" alt="salvar_db" border="0" width=80% height=80%>
</p>

3. N√£o feche a janela e espere a opera√ß√£o ser conclu√≠da. Ap√≥s a conclus√£o, o sistema ir√° exibir uma mensagem de sucesso. Caso ocorra algum erro, tente novamente.

<p align="center">
  <img src="assets/dashboard/importar_banco_de_dados/importar_bd_3.JPG" alt="salvar_db" border="0" width=80% height=80%>
</p>


## üìÅ Estrutura de pastas

Dentre os arquivos e pastas presentes na raiz do projeto, definem-se:

- <b>.streamlit</b>: Pasta que cont√©m arquivos de configura√ß√£o do Streamlit, como o tema da interface e a organiza√ß√£o da barra lateral.
- <b>assets</b>: Diret√≥rio destinado ao armazenamento de elementos n√£o estruturados do projeto, como imagens e √≠cones utilizados no dashboard.
- <b>iac</b>: Pasta que cont√©m os arquivos de infraestrutura como c√≥digo (IaC) desenvolvidos em Terraform, utilizados para provisionar e gerenciar a infraestrutura necess√°ria para o funcionamento do sistema na nuvem.
- <b>src</b>: Diret√≥rio principal que cont√©m todo o c√≥digo-fonte desenvolvido ao longo das fases do projeto. Ele est√° organizado nos seguintes subm√≥dulos:
  - <b>dashboard</b>: C√≥digo respons√°vel pela constru√ß√£o do dashboard, desenvolvido em Python com uso da biblioteca Streamlit. ([dashboard](src/dashboard/))
  - <b>database</b>: M√≥dulo respons√°vel pelas opera√ß√µes de banco de dados, incluindo conex√µes, inser√ß√µes, listagens, edi√ß√µes e exclus√µes de registros.
  - <b>logger</b>: C√≥digo respons√°vel por registrar (logar) todas as opera√ß√µes executadas no sistema, garantindo rastreabilidade.
  - <b>machine_learning</b>: Cont√©m o c√≥digo e notebooks relacionados ao desenvolvimento e treinamento dos modelos de Machine Learning.
  - <b>plots</b>: Cont√©m o c√≥digo respons√°vel pela gera√ß√£o de gr√°ficos e visualiza√ß√µes, utilizado para exibir dados de forma clara e intuitiva no dashboard.
  - <b>wokwi</b>: Cont√©m o c√≥digo do sensor ESP32 utilizado na simula√ß√£o de sensores.
  - <b>wokwi_api</b>: Cont√©m o c√≥digo respons√°vel por criar a API que vai salvar as leituras dos sensores no banco de dados.
- <b>.dockerignore</b>: Arquivo que especifica quais arquivos e pastas devem ser ignorados pelo Docker ao construir a imagem do container, ajudando a reduzir o tamanho da imagem e evitar a inclus√£o de arquivos desnecess√°rios.
- <b>.env</b>: Arquivo de configura√ß√£o que cont√©m as chaves de API e outras vari√°veis de ambiente necess√°rias para o funcionamento do sistema. √â necess√°rio criar este arquivo na raiz do projeto, conforme orienta√ß√µes na se√ß√£o "Arquivo de Configura√ß√£o".
- <b>.gitignore</b>: Arquivo que especifica quais arquivos e pastas devem ser ignorados pelo Git, evitando que informa√ß√µes sens√≠veis ou desnecess√°rias sejam versionadas. √â importante garantir que o arquivo `.env` esteja inclu√≠do neste arquivo para evitar o upload de chaves de API e outras informa√ß√µes sens√≠veis.
- <b>deploy_app_server.bat</b>: Script em batch que automatiza o processo de deploy da aplica√ß√£o no servidor EC2 na AWS, incluindo a c√≥pia dos arquivos necess√°rios e a configura√ß√£o do ambiente.
- <b>Dockerfile</b>: Arquivo que define a imagem Docker para o projeto e suas depend√™ncias, permitindo a cria√ß√£o de containers consistentes para execu√ß√£o do sistema.
- <b>docker-compose.yml</b>: Arquivo de configura√ß√£o do Docker Compose que define os servi√ßos, redes e volumes necess√°rios para executar o sistema em containers Docker.
- <b>README</b>: Arquivo de documenta√ß√£o do projeto (este que est√° sendo lido), com orienta√ß√µes gerais, instru√ß√µes de uso e contextualiza√ß√£o.
- <b>main_dash</b>: Arquivo principal para a execu√ß√£o do dashboard. Est√° localizado na raiz do projeto com o objetivo de evitar problemas com importa√ß√µes de m√≥dulos internos.
- <b>requirements.txt</b>: Arquivo que lista todas as depend√™ncias do projeto, necess√°rio para a instala√ß√£o do ambiente virtual. Deve ser utilizado com o comando `pip install -r requirements.txt` para instalar as bibliotecas necess√°rias.

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>
